{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🌍 Global Warming Data Analysis Project\n",
    "\n",
    "## Integrating Python Day 1 & Day 2 Concepts\n",
    "\n",
    "This comprehensive project demonstrates all concepts learned in:\n",
    "- **Day 1**: Python basics, data types, data structures (lists, tuples, sets, ranges)\n",
    "- **Day 2**: Functions, packages, NumPy arrays, vectorization, lambda functions\n",
    "\n",
    "### Project Overview\n",
    "We'll analyze 145 years of global temperature data to:\n",
    "1. Understand warming trends\n",
    "2. Analyze acceleration of climate change\n",
    "3. Assess city-specific impacts\n",
    "4. Generate future projections\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📦 Import Required Packages\n",
    "\n",
    "First, we'll import the packages we need. These demonstrate Day 2's concept of leveraging Python's ecosystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 2 Concept: Importing packages\n",
    "import numpy as np  # For numerical computing\n",
    "import random      # For generating random variations\n",
    "from datetime import datetime, timedelta  # For date operations\n",
    "import math        # For mathematical functions\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"✅ Packages imported successfully!\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Data Generation & Structures\n",
    "\n",
    "### Day 1 Concepts Applied:\n",
    "- **Lists**: Ordered, mutable collections for temperature data\n",
    "- **Tuples**: Immutable records for (year, temperature, anomaly)\n",
    "- **Sets**: Unique decades\n",
    "- **Ranges**: Efficient year generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_temperature_data():\n",
    "    \"\"\"\n",
    "    Generate synthetic global temperature data using Day 1 concepts.\n",
    "    Returns multiple data structures for analysis.\n",
    "    \"\"\"\n",
    "    print(\"🌍 GLOBAL WARMING DATA ANALYSIS PROJECT\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"\\n📊 Generating Temperature Data...\")\n",
    "    \n",
    "    # Day 1 Concepts: Lists for storing sequences\n",
    "    years = list(range(1880, 2025))  # Historical years\n",
    "    cities = [\"New York\", \"London\", \"Tokyo\", \"Sydney\", \"Mumbai\", \"Cairo\", \"São Paulo\", \"Moscow\"]\n",
    "    \n",
    "    # Generate base temperatures with warming trend\n",
    "    base_temp = 14.0  # Global average in Celsius (1880)\n",
    "    warming_rate = 0.01  # Degrees per year\n",
    "    \n",
    "    # Create temperature records as list of tuples (Day 1: tuples for fixed records)\n",
    "    temperature_records = []\n",
    "    \n",
    "    for i, year in enumerate(years):\n",
    "        # Add warming trend + random variation\n",
    "        annual_temp = base_temp + (warming_rate * i) + random.uniform(-0.5, 0.5)\n",
    "        \n",
    "        # Create tuple: (year, temperature, anomaly)\n",
    "        anomaly = annual_temp - base_temp\n",
    "        record = (year, round(annual_temp, 2), round(anomaly, 2))\n",
    "        temperature_records.append(record)\n",
    "    \n",
    "    # Day 1 Concept: Sets for unique values\n",
    "    decade_set = set(year // 10 * 10 for year in years)\n",
    "    \n",
    "    print(f\"✓ Generated {len(temperature_records)} years of data\")\n",
    "    print(f\"✓ Tracking {len(cities)} cities\")\n",
    "    print(f\"✓ Covering {len(decade_set)} decades\")\n",
    "    \n",
    "    return temperature_records, cities, decade_set\n",
    "\n",
    "# Generate the data\n",
    "records, cities, decades = generate_temperature_data()\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\n📌 Sample Records (first 5 and last 5):\")\n",
    "print(\"Year | Temperature | Anomaly\")\n",
    "print(\"-\" * 30)\n",
    "for record in records[:3]:\n",
    "    print(f\"{record[0]} | {record[1]:.2f}°C | {record[2]:+.2f}°C\")\n",
    "print(\"...\")\n",
    "for record in records[-3:]:\n",
    "    print(f\"{record[0]} | {record[1]:.2f}°C | {record[2]:+.2f}°C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Functions for Data Processing\n",
    "\n",
    "### Day 2 Concepts:\n",
    "- **Functions with clear purpose**: Modular, reusable code\n",
    "- **Parameters and return values**: Input/output handling\n",
    "- **Docstrings**: Clear documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_decade_averages(records):\n",
    "    \"\"\"\n",
    "    Day 2 Concept: Function with clear purpose\n",
    "    Calculate average temperatures by decade.\n",
    "    \"\"\"\n",
    "    decade_temps = {}\n",
    "    \n",
    "    for year, temp, anomaly in records:\n",
    "        decade = year // 10 * 10\n",
    "        if decade not in decade_temps:\n",
    "            decade_temps[decade] = []\n",
    "        decade_temps[decade].append(temp)\n",
    "    \n",
    "    # Calculate averages\n",
    "    decade_averages = {}\n",
    "    for decade, temps in decade_temps.items():\n",
    "        decade_averages[decade] = round(sum(temps) / len(temps), 2)\n",
    "    \n",
    "    return decade_averages\n",
    "\n",
    "# Calculate and display decade averages\n",
    "decade_avgs = calculate_decade_averages(records)\n",
    "\n",
    "print(\"📊 Average Temperature by Decade:\")\n",
    "print(\"=\" * 35)\n",
    "for decade in sorted(decade_avgs.keys()):\n",
    "    avg_temp = decade_avgs[decade]\n",
    "    bar = \"█\" * int((avg_temp - 13) * 10)  # Simple bar chart\n",
    "    print(f\"{decade}s: {avg_temp:.2f}°C {bar}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_warming_acceleration(records, window_size=30):\n",
    "    \"\"\"\n",
    "    Day 2 Concept: Function with parameters\n",
    "    Analyze the rate of warming over time using moving windows.\n",
    "    \"\"\"\n",
    "    years = [r[0] for r in records]\n",
    "    temps = [r[1] for r in records]\n",
    "    \n",
    "    warming_rates = []\n",
    "    \n",
    "    for i in range(len(records) - window_size):\n",
    "        window_years = years[i:i+window_size]\n",
    "        window_temps = temps[i:i+window_size]\n",
    "        \n",
    "        # Simple linear regression (slope)\n",
    "        n = len(window_years)\n",
    "        sum_x = sum(window_years)\n",
    "        sum_y = sum(window_temps)\n",
    "        sum_xy = sum(x*y for x, y in zip(window_years, window_temps))\n",
    "        sum_x2 = sum(x**2 for x in window_years)\n",
    "        \n",
    "        slope = (n*sum_xy - sum_x*sum_y) / (n*sum_x2 - sum_x**2)\n",
    "        warming_rates.append((window_years[window_size//2], round(slope * 10, 3)))  # Per decade\n",
    "    \n",
    "    return warming_rates\n",
    "\n",
    "# Analyze warming acceleration\n",
    "warming_rates = analyze_warming_acceleration(records)\n",
    "\n",
    "print(\"📈 Warming Acceleration Analysis\")\n",
    "print(\"Sample warming rates (°C per decade):\")\n",
    "print(\"-\" * 40)\n",
    "# Show rates from different periods\n",
    "sample_indices = [0, len(warming_rates)//3, 2*len(warming_rates)//3, -1]\n",
    "for idx in sample_indices:\n",
    "    year, rate = warming_rates[idx]\n",
    "    print(f\"Around {year}: {rate:.3f}°C/decade\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: NumPy Operations\n",
    "\n",
    "### Day 2 Advanced Concepts:\n",
    "- **NumPy arrays**: Efficient numerical computing\n",
    "- **Vectorization**: Operations without loops\n",
    "- **Boolean indexing**: Powerful filtering\n",
    "- **Statistical functions**: Built-in analysis tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_climate_analysis(records):\n",
    "    \"\"\"\n",
    "    Day 2 Concept: NumPy for efficient numerical computing\n",
    "    Perform vectorized operations on temperature data.\n",
    "    \"\"\"\n",
    "    print(\"🔬 NumPy Analysis (Vectorized Operations)\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Convert to NumPy arrays\n",
    "    years = np.array([r[0] for r in records])\n",
    "    temps = np.array([r[1] for r in records])\n",
    "    anomalies = np.array([r[2] for r in records])\n",
    "    \n",
    "    # Vectorized operations (Day 2: No loops needed!)\n",
    "    print(f\"\\n📊 Temperature Statistics:\")\n",
    "    print(f\"  Mean: {np.mean(temps):.2f}°C\")\n",
    "    print(f\"  Std Dev: {np.std(temps):.2f}°C\")\n",
    "    print(f\"  Min: {np.min(temps):.2f}°C (Year {years[np.argmin(temps)]})\")\n",
    "    print(f\"  Max: {np.max(temps):.2f}°C (Year {years[np.argmax(temps)]})\")\n",
    "    print(f\"  Median: {np.median(temps):.2f}°C\")\n",
    "    print(f\"  25th percentile: {np.percentile(temps, 25):.2f}°C\")\n",
    "    print(f\"  75th percentile: {np.percentile(temps, 75):.2f}°C\")\n",
    "    \n",
    "    # Boolean indexing (Day 2: NumPy's superpower)\n",
    "    warm_years = years[temps > np.mean(temps)]\n",
    "    very_warm_years = years[temps > np.percentile(temps, 90)]\n",
    "    \n",
    "    print(f\"\\n🔥 Warming Trends:\")\n",
    "    print(f\"  Years above average: {len(warm_years)} ({len(warm_years)/len(years)*100:.1f}%)\")\n",
    "    print(f\"  Years in top 10%: {len(very_warm_years)}\")\n",
    "    print(f\"  Hottest years: {sorted(very_warm_years[-5:])}\")\n",
    "    \n",
    "    # Recent vs historical comparison\n",
    "    historical = temps[:50]  # First 50 years\n",
    "    recent = temps[-50:]      # Last 50 years\n",
    "    \n",
    "    print(f\"\\n📈 Historical vs Recent (50-year periods):\")\n",
    "    print(f\"  Historical avg (1880-1929): {np.mean(historical):.2f}°C\")\n",
    "    print(f\"  Recent avg (1975-2024): {np.mean(recent):.2f}°C\")\n",
    "    print(f\"  Warming: +{np.mean(recent) - np.mean(historical):.2f}°C\")\n",
    "    print(f\"  Volatility increase: {np.std(recent) - np.std(historical):.3f}°C\")\n",
    "    \n",
    "    # Cumulative warming\n",
    "    cumulative_anomaly = np.cumsum(anomalies)\n",
    "    \n",
    "    return years, temps, anomalies, cumulative_anomaly\n",
    "\n",
    "# Perform NumPy analysis\n",
    "numpy_results = numpy_climate_analysis(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Lambda Functions & Filtering\n",
    "\n",
    "### Day 2 Concepts:\n",
    "- **Lambda functions**: Quick one-line functions\n",
    "- **Filter function**: Applying conditions to data\n",
    "- **List comprehensions**: Pythonic data filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filters_and_transformations(records):\n",
    "    \"\"\"\n",
    "    Day 2 Concept: Lambda functions for quick operations\n",
    "    \"\"\"\n",
    "    print(\"🔍 Data Filtering & Transformations\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Lambda functions for conversions\n",
    "    celsius_to_fahrenheit = lambda c: c * 9/5 + 32\n",
    "    classify_temp = lambda t: \"🔥 Hot\" if t > 15.5 else (\"🌡️ Warm\" if t > 14.5 else \"❄️ Cool\")\n",
    "    \n",
    "    # Filter extreme years\n",
    "    extreme_filter = lambda r: abs(r[2]) > 1.0  # Anomaly > 1°C\n",
    "    extreme_years = list(filter(extreme_filter, records))\n",
    "    \n",
    "    print(f\"\\n⚠️ Extreme anomaly years (|anomaly| > 1°C): {len(extreme_years)}\")\n",
    "    print(f\"Percentage of extreme years: {len(extreme_years)/len(records)*100:.1f}%\")\n",
    "    \n",
    "    # Transform recent data\n",
    "    recent_records = records[-10:]\n",
    "    print(\"\\n📅 Last 10 Years Analysis:\")\n",
    "    print(\"Year | Temp (°C/°F) | Classification | Anomaly\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for year, temp, anomaly in recent_records:\n",
    "        temp_f = celsius_to_fahrenheit(temp)\n",
    "        classification = classify_temp(temp)\n",
    "        print(f\"{year} | {temp:.1f}°C ({temp_f:.1f}°F) | {classification} | {anomaly:+.2f}°C\")\n",
    "    \n",
    "    # Using list comprehension (Pythonic filtering)\n",
    "    recent_hot_years = [year for year, temp, _ in recent_records if temp > 15.5]\n",
    "    print(f\"\\nHot years in last decade: {recent_hot_years}\")\n",
    "    \n",
    "    return extreme_years\n",
    "\n",
    "# Apply filters and transformations\n",
    "extreme_years = apply_filters_and_transformations(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: City-Specific Impact Analysis\n",
    "\n",
    "### Combining Day 1 & Day 2 Concepts:\n",
    "- Multiple data structures working together\n",
    "- Functions processing complex data\n",
    "- List comprehensions for filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_city_impacts(cities, global_warming_increase):\n",
    "    \"\"\"\n",
    "    Simulate warming impacts on different cities.\n",
    "    Combines multiple data structures (Day 1).\n",
    "    \"\"\"\n",
    "    print(\"\\n🏙️ City-Specific Impact Analysis\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # City data: (city, base_temp, vulnerability_score)\n",
    "    city_data = [\n",
    "        (\"New York\", 12.5, 0.7),\n",
    "        (\"London\", 10.5, 0.6),\n",
    "        (\"Tokyo\", 16.0, 0.8),\n",
    "        (\"Sydney\", 18.0, 0.7),\n",
    "        (\"Mumbai\", 27.0, 0.9),\n",
    "        (\"Cairo\", 22.0, 0.85),\n",
    "        (\"São Paulo\", 19.0, 0.75),\n",
    "        (\"Moscow\", 5.5, 0.5)\n",
    "    ]\n",
    "    \n",
    "    impacts = []\n",
    "    \n",
    "    for city, base_temp, vulnerability in city_data:\n",
    "        # Calculate projected temperature\n",
    "        projected_temp = base_temp + (global_warming_increase * vulnerability)\n",
    "        \n",
    "        # Risk assessment\n",
    "        if projected_temp > 30:\n",
    "            risk = \"🔴 CRITICAL\"\n",
    "        elif projected_temp > 25:\n",
    "            risk = \"🟠 HIGH\"\n",
    "        elif projected_temp > 20:\n",
    "            risk = \"🟡 MODERATE\"\n",
    "        else:\n",
    "            risk = \"🟢 LOW\"\n",
    "        \n",
    "        impacts.append({\n",
    "            \"city\": city,\n",
    "            \"current\": base_temp,\n",
    "            \"projected\": round(projected_temp, 1),\n",
    "            \"increase\": round(projected_temp - base_temp, 1),\n",
    "            \"risk\": risk\n",
    "        })\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\nProjected warming: +{global_warming_increase}°C globally\")\n",
    "    print(\"\\n\" + \"City\".ljust(12) + \"Current  Projected  Increase  Risk\")\n",
    "    print(\"-\" * 55)\n",
    "    \n",
    "    for impact in impacts:\n",
    "        city_str = impact['city'].ljust(12)\n",
    "        current_str = f\"{impact['current']:.1f}°C\".ljust(9)\n",
    "        projected_str = f\"{impact['projected']:.1f}°C\".ljust(11)\n",
    "        increase_str = f\"+{impact['increase']:.1f}°C\".ljust(10)\n",
    "        print(f\"{city_str}{current_str}{projected_str}{increase_str}{impact['risk']}\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    critical_cities = [i for i in impacts if \"CRITICAL\" in i[\"risk\"]]\n",
    "    high_risk_cities = [i for i in impacts if \"HIGH\" in i[\"risk\"]]\n",
    "    \n",
    "    print(f\"\\n📊 Risk Summary:\")\n",
    "    print(f\"  Cities at CRITICAL risk: {len(critical_cities)}\")\n",
    "    print(f\"  Cities at HIGH risk: {len(high_risk_cities)}\")\n",
    "    \n",
    "    return impacts\n",
    "\n",
    "# Simulate city impacts with 2.5°C warming\n",
    "projected_warming = 2.5\n",
    "city_impacts = simulate_city_impacts(cities, projected_warming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Comprehensive Climate Report\n",
    "\n",
    "### Bringing It All Together:\n",
    "This final section combines all our analyses into a comprehensive report, demonstrating how all Day 1 and Day 2 concepts work together in a real-world application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_climate_report(records, numpy_results, city_impacts):\n",
    "    \"\"\"\n",
    "    Generate a comprehensive climate report combining all analyses.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"🌡️ COMPREHENSIVE CLIMATE REPORT\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    years, temps, anomalies, cumulative = numpy_results\n",
    "    \n",
    "    # Key findings\n",
    "    print(\"\\n📊 KEY FINDINGS:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # 1. Overall warming trend\n",
    "    total_warming = temps[-1] - temps[0]\n",
    "    years_span = years[-1] - years[0]\n",
    "    rate_per_decade = (total_warming / years_span) * 10\n",
    "    \n",
    "    print(f\"\\n1. Total Warming ({years[0]}-{years[-1]}): +{total_warming:.2f}°C\")\n",
    "    print(f\"   Rate: {rate_per_decade:.3f}°C per decade\")\n",
    "    \n",
    "    # 2. Acceleration analysis\n",
    "    early_period = temps[:30]\n",
    "    late_period = temps[-30:]\n",
    "    acceleration = np.std(late_period) - np.std(early_period)\n",
    "    \n",
    "    print(f\"\\n2. Volatility Change:\")\n",
    "    print(f\"   Early period std: {np.std(early_period):.3f}°C\")\n",
    "    print(f\"   Recent period std: {np.std(late_period):.3f}°C\")\n",
    "    print(f\"   Increased volatility: {acceleration:.3f}°C\")\n",
    "    \n",
    "    # 3. Threshold breaches\n",
    "    threshold_15 = np.sum(temps > 15.0)\n",
    "    threshold_16 = np.sum(temps > 16.0)\n",
    "    \n",
    "    print(f\"\\n3. Temperature Thresholds:\")\n",
    "    print(f\"   Years above 15°C: {threshold_15} ({threshold_15/len(temps)*100:.1f}%)\")\n",
    "    print(f\"   Years above 16°C: {threshold_16} ({threshold_16/len(temps)*100:.1f}%)\")\n",
    "    \n",
    "    # 4. Projections\n",
    "    if rate_per_decade > 0:\n",
    "        years_to_2c = (2.0 - total_warming) / (rate_per_decade / 10)\n",
    "        year_2c = int(years[-1] + years_to_2c) if years_to_2c > 0 else \"Already exceeded\"\n",
    "    else:\n",
    "        year_2c = \"N/A\"\n",
    "    \n",
    "    print(f\"\\n4. Future Projections:\")\n",
    "    print(f\"   Expected year to reach +2°C: {year_2c}\")\n",
    "    print(f\"   2050 projected increase: +{rate_per_decade * 2.5:.2f}°C from today\")\n",
    "    \n",
    "    # 5. City impacts summary\n",
    "    print(f\"\\n5. Urban Impact Summary:\")\n",
    "    critical_count = sum(1 for c in city_impacts if \"CRITICAL\" in c[\"risk\"])\n",
    "    high_count = sum(1 for c in city_impacts if \"HIGH\" in c[\"risk\"])\n",
    "    \n",
    "    print(f\"   Cities analyzed: {len(city_impacts)}\")\n",
    "    print(f\"   Critical risk: {critical_count}\")\n",
    "    print(f\"   High risk: {high_count}\")\n",
    "    \n",
    "    # Most vulnerable cities\n",
    "    sorted_cities = sorted(city_impacts, key=lambda x: x[\"increase\"], reverse=True)\n",
    "    print(f\"\\n   Most affected cities:\")\n",
    "    for city in sorted_cities[:3]:\n",
    "        print(f\"   • {city['city']}: +{city['increase']:.1f}°C (Risk: {city['risk']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"📌 RECOMMENDATIONS:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"1. Immediate action required for cities at CRITICAL risk\")\n",
    "    print(\"2. Implement adaptation strategies for +2°C warming\")\n",
    "    print(f\"3. Focus on reducing warming rate (currently {rate_per_decade:.3f}°C/decade)\")\n",
    "    print(\"4. Prepare for increased climate volatility\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Generate the comprehensive report\n",
    "generate_climate_report(records, numpy_results, city_impacts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎓 Learning Summary\n",
    "\n",
    "### Concepts Successfully Demonstrated:\n",
    "\n",
    "#### **Day 1 Concepts:**\n",
    "- ✅ **Data Types**: Integers (years), Floats (temperatures), Strings (city names), Booleans (conditions)\n",
    "- ✅ **Lists**: Temperature records, cities, years\n",
    "- ✅ **Tuples**: Immutable records (year, temp, anomaly)\n",
    "- ✅ **Sets**: Unique decades\n",
    "- ✅ **Ranges**: Efficient year generation\n",
    "- ✅ **F-strings**: Professional output formatting\n",
    "\n",
    "#### **Day 2 Concepts:**\n",
    "- ✅ **Functions**: Modular, reusable code with clear purposes\n",
    "- ✅ **Parameters**: Input handling and default values\n",
    "- ✅ **NumPy Arrays**: Efficient numerical computing\n",
    "- ✅ **Vectorization**: Operations without loops\n",
    "- ✅ **Boolean Indexing**: Powerful data filtering\n",
    "- ✅ **Lambda Functions**: Quick one-line operations\n",
    "- ✅ **Package Imports**: Leveraging Python's ecosystem\n",
    "\n",
    "### Real-World Skills Applied:\n",
    "1. **Time Series Analysis**: 145 years of temperature data\n",
    "2. **Statistical Analysis**: Mean, std dev, percentiles\n",
    "3. **Trend Analysis**: Warming rates and acceleration\n",
    "4. **Risk Assessment**: City vulnerability scoring\n",
    "5. **Data Visualization**: Clear, formatted outputs\n",
    "6. **Report Generation**: Actionable insights and recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Next Steps & Enhancements\n",
    "\n",
    "### You Can Extend This Project With:\n",
    "\n",
    "1. **Data Visualization** (Coming in your course):\n",
    "   - Add matplotlib graphs for temperature trends\n",
    "   - Create heatmaps for city impacts\n",
    "   - Plot warming acceleration over time\n",
    "\n",
    "2. **Real Data Integration**:\n",
    "   - Load actual climate data from CSV files\n",
    "   - Connect to climate APIs\n",
    "   - Use pandas DataFrames (Day 4+)\n",
    "\n",
    "3. **Advanced Analysis**:\n",
    "   - Machine learning predictions\n",
    "   - Seasonal decomposition\n",
    "   - Regional clustering\n",
    "\n",
    "4. **Interactive Features**:\n",
    "   - User input for city selection\n",
    "   - Custom date ranges\n",
    "   - Scenario modeling\n",
    "\n",
    "### Key Takeaway:\n",
    "**With just 2 days of Python knowledge, you've built a meaningful tool to analyze one of humanity's most pressing challenges!** 🌍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final celebration!\n",
    "print(\"\\n\" + \"🎉\" * 30)\n",
    "print(\"\\n✅ PROJECT COMPLETE!\")\n",
    "print(\"\\nYou've successfully integrated:\")\n",
    "print(\"  • Day 1: All basic Python concepts\")\n",
    "print(\"  • Day 2: Functions, NumPy, and advanced features\")\n",
    "print(\"  • Real-world application: Climate change analysis\")\n",
    "print(\"\\nGreat job! You're ready for Day 3 and beyond! 🚀\")\n",
    "print(\"\\n\" + \"🎉\" * 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
